# âš ï¸ ORIGINAL BRIEFING (Historical Reference)

> **âš ï¸ LEGACY DOCUMENT**: Este es el briefing ORIGINAL del proyecto (Oct 2025). Contiene referencias a "V1" porque fue creado cuando el proyecto apenas comenzaba.
>
> **Estado actual**: El sistema evolucionÃ³ a documentar la aplicaciÃ³n COMPLETA desde el inicio. Ver [SYSTEM-OVERVIEW.md](../01-foundation/SYSTEM-OVERVIEW.md) para la descripciÃ³n actual.
>
> **RazÃ³n de existencia**: Referencia histÃ³rica del approach original y contexto del proyecto.

---

# Briefing: Finance App - Simple pero Completa
**Date**: 2025-10-28
**Purpose**: DocumentaciÃ³n completa para implementar el finance app
**Approach**: Example-first, Abstract-later
**Target**: Nueva carpeta, nueva sesiÃ³n, desde cero

---

## ğŸ¯ Executive Summary

**Tu MisiÃ³n:**
Crear documentaciÃ³n completa (specs, batches, flows, storytelling) para **Finance App V1**:
- âœ… **Simple**: Hardcoded OK, ~1800 LOC, SQLite
- âœ… **Completa**: Todas las features que Darwin necesita dÃ­a a dÃ­a + pipeline completo
- âœ… **Timeline Continuo**: Cargar 2 aÃ±os histÃ³ricos + continuar con nuevos statements (UN SOLO FLUJO)
- âœ… **Truth Construction**: Pipeline automÃ¡tico (Upload â†’ Parse â†’ Observe â†’ Cluster â†’ Normalize â†’ Canonical)

**NO vas a escribir cÃ³digo.** Solo documentaciÃ³n detallada para que alguien pueda implementarlo.

**Entregables:**
- 10 batch documents (foundation â†’ pipeline â†’ UI)
- 5 user flows (timeline continuo)
- 4 parser specs (BofA, Apple, Wise, Scotia)
- 1 storytelling completo (Darwin usando el app)
- Technical specs (pipeline, clustering, normalization, transfers, currency)

---

## ğŸ“– Context: De DÃ³nde Venimos

### **Trabajo Anterior (NO usar directamente)**
Existe carpeta `/Users/darwinborges/Description/` con:
- 23 verticals (diseÃ±ados con abstracciones predefinidas)
- 57 OL primitives (maquinaria universal pre-diseÃ±ada)
- 3 systems (truth-construction, audit, api-auth)
- Comprehensive storytelling (2,376 lÃ­neas)

**Problema:**
Ese approach era **"diseÃ±ar abstracciones primero, luego app"**.

**Nuevo approach:**
**"Construir app simple primero, luego extraer abstracciones"**.

### **QuÃ© Puedes Usar del Trabajo Anterior**
âœ… **User journeys** - QuÃ© necesita Darwin (sigue siendo vÃ¡lido)
âœ… **Edge cases** - Casos reales que el app debe manejar
âœ… **Domain knowledge** - CÃ³mo funcionan bancos, statements, transfers
âŒ **Abstracciones prediseÃ±adas** - NO usar primitivos/systems ya diseÃ±ados
âŒ **Separation app/machinery** - V1 es TODO hardcoded, no hay separaciÃ³n todavÃ­a

---

## ğŸŒŸ Vision & Core Philosophy

### **1. Timeline Continuo (NO separaciÃ³n histÃ³rico vs diario)**

**Principio Fundamental:**
> NO hay diferencia entre "cargar statements histÃ³ricos" y "usar el app dÃ­a a dÃ­a".
> Es UN SOLO FLUJO que funciona para cualquier fecha.

**Ejemplo Concreto:**
```
Darwin puede hacer esto en CUALQUIER orden:

DÃ­a 1: Sube BofA_Oct2024.pdf (este mes)
DÃ­a 2: Sube BofA_Oct2022.pdf (hace 2 aÃ±os)
DÃ­a 3: Sube BofA_Nov2024.pdf (prÃ³ximo mes)
DÃ­a 4: Busca "Uber" â†’ encuentra matches de 2022, 2023, 2024
DÃ­a 5: Dashboard muestra trend completo (2022-2024)

Todo en el mismo timeline, misma vista, mismo flujo.
```

**Implicaciones TÃ©cnicas:**
- âœ… Upload funciona igual con statement de 2022 o 2024
- âœ… Transaction list muestra TODO el timeline (sin paginaciÃ³n temporal)
- âœ… BÃºsqueda funciona sobre TODO el periodo disponible
- âœ… Dashboard calcula trends sobre TODO el periodo
- âœ… Transfer detection busca en TODO el timeline
- âŒ NO hay "modo setup" vs "modo daily use"
- âŒ NO hay botÃ³n "importar histÃ³ricos" separado

---

### **2. Simple pero Completa**

**DefiniciÃ³n de "Simple":**
- Hardcoded OK (ej: currency rate = 0.058 hardcoded)
- SQLite (no PostgreSQL, no Redis)
- ~1500 LOC total
- Un archivo por parser (bofa.py con regex hardcoded)
- Funciones directas (no clases abstractas complejas)

**DefiniciÃ³n de "Completa":**
- âœ… Soporta 4 bancos de Darwin (BofA, Apple Card, Wise, Scotia)
- âœ… Soporta 2 currencies (USD, MXN)
- âœ… Todas las features necesarias para uso diario:
  - Upload statements
  - Ver transacciones (list + detail)
  - Buscar/filtrar (por merchant, date, amount, category)
  - Categorizar gastos
  - Detectar transfers automÃ¡ticamente
  - Convertir currencies (MXN â†” USD)
  - Dashboard con trends mensuales
- âœ… Maneja casos edge reales (duplicates, corrupted PDFs, layout changes)

**NO incluye (fuera de scope V1):**
- âŒ API pÃºblica (solo web UI)
- âŒ Multi-user (solo Darwin)
- âŒ Real-time sync con bancos
- âŒ Mobile app
- âŒ ML/predictions
- âŒ Budgets/forecasting avanzado
- âŒ Audit trails detallados (ProvenanceLedger)

---

### **3. Example-First, Abstract-Later Methodology**

**Proceso:**

**Fase 1 (V1 - Tu trabajo ahora):**
```python
# Hardcoded, directo, simple
def parse_bofa_statement(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        text = pdf.pages[0].extract_text()

        # Regex hardcoded especÃ­fico para BofA
        pattern = r'(\d{2}/\d{2})\s+(.+?)\s+(-?\$[\d,]+\.\d{2})'
        matches = re.findall(pattern, text)

        transactions = []
        for date, merchant, amount in matches:
            transactions.append({
                'date': f"2024-{date}",  # Year hardcoded
                'merchant': merchant,
                'amount': float(amount.replace('$','').replace(',',''))
            })

        return transactions

# Similar para apple_card, wise, scotia (copy-paste + modify regex)
```

**Fase 2 (V2 - Futuro, NO ahora):**
```python
# DespuÃ©s de ver quÃ© se repite, abstraer
class Parser:
    def parse(self, pdf_path):
        raise NotImplementedError

class BofAParser(Parser):
    def parse(self, pdf_path):
        # Same logic, pero ahora en clase
        ...

# V2 usa abstracciones emergentes (no prediseÃ±adas)
```

**Tu trabajo es SOLO Fase 1 (V1).**

---

## ğŸ—ï¸ Truth Construction Pipeline (Core Architecture)

### **Why Pipeline is Necessary**

**Problem without pipeline:**
```sql
-- Single table approach (incomplete)
CREATE TABLE transactions (
    merchant TEXT  -- Â¿"UBER *EATS" (raw) o "Uber Eats" (clean)?
);

-- If you store raw â†’ UI looks ugly
-- If you store clean â†’ you lost original data
-- If you change normalization rule â†’ can't re-process
```

**Solution with pipeline:**
```
Upload â†’ Parse â†’ ObservationStore (raw, AS-IS)
                      â†“
                  Clustering (group similar)
                      â†“
                  Normalization (apply rules)
                      â†“
              CanonicalStore (truth, clean)
```

---

### **Pipeline Stages (4 steps, each simple)**

#### **Stage 1: Parse â†’ ObservationStore**
```python
# Extract raw data from PDF (AS-IS)
def parse_and_store(pdf_path):
    """Extract transactions as-is from PDF."""
    raw_transactions = parser.parse(pdf_path)

    # Store exactly as extracted (no cleaning)
    for raw in raw_transactions:
        db.execute("""
            INSERT INTO observations (obs_id, upload_id, row_id,
                                      date, raw_merchant, amount, currency)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (generate_id(), upload_id, raw['row'],
              raw['date'], raw['merchant'], raw['amount'], 'USD'))

    return raw_transactions

# Example stored observation:
# obs_id: "obs_123"
# raw_merchant: "UBER *EATS"  (exactly as in PDF)
# amount: -15.00
```

---

#### **Stage 2: Clustering**
```python
# Group similar merchant names (simple string similarity)
def cluster_merchants(observations):
    """Group merchant variants using string similarity."""
    clusters = {}

    for obs in observations:
        merchant = obs['raw_merchant']
        # Normalize for comparison
        normalized = merchant.upper().replace('*', '').replace('-', ' ').strip()

        # Find existing similar cluster
        found = False
        for cluster_id, members in clusters.items():
            if string_similarity(normalized, cluster_id) > 0.80:
                members.append(merchant)
                found = True
                break

        if not found:
            clusters[normalized] = [merchant]

    return clusters

# Example output:
# {
#     "UBER EATS": ["UBER *EATS", "UberEATS", "Uber Eats", "UBER EATS SF"],
#     "STARBUCKS": ["STARBUCKS", "STARBUCKS STORE 1234", "Starbucks Coffee"]
# }

def string_similarity(a, b):
    """Simple Levenshtein distance (edit distance)."""
    # Standard algorithm, ~20 LOC
    # Returns 0.0-1.0 (1.0 = identical)
    ...
```

**Why clustering is simple:**
- No ML, no training data needed
- Just string comparison (edit distance)
- ~50 LOC total
- Hardcoded threshold (80% similarity) OK

---

#### **Stage 3: Normalization**
```python
# Apply rules to create canonical version
def normalize(observation, clusters):
    """Normalize using clusters + rules."""
    raw_merchant = observation['raw_merchant']

    # Step 1: Check cluster
    canonical = clusters.get_canonical(raw_merchant)
    category = None

    # Step 2: Apply regex rules (higher priority)
    for rule in load_normalization_rules():
        if re.match(rule['pattern'], raw_merchant, re.IGNORECASE):
            canonical = rule['canonical']
            category = rule['category']
            break

    # Step 3: Fallback to title case
    if not canonical:
        canonical = raw_merchant.title()

    return {
        'obs_id': observation['obs_id'],
        'canonical_merchant': canonical,
        'category': category or 'Uncategorized'
    }

# Example:
# Input:  obs_id="obs_123", raw_merchant="UBER *EATS"
# Output: canonical_merchant="Uber Eats", category="Food & Dining"
```

**Normalization rules (JSON):**
```json
{
  "rules": [
    {
      "pattern": "UBER.*EATS",
      "canonical": "Uber Eats",
      "category": "Food & Dining",
      "priority": 2
    },
    {
      "pattern": "UBER.*",
      "canonical": "Uber",
      "category": "Transportation",
      "priority": 1
    },
    {
      "pattern": "STARBUCKS.*",
      "canonical": "Starbucks",
      "category": "Food & Dining",
      "priority": 1
    }
  ]
}
```

---

#### **Stage 4: CanonicalStore**
```python
# Store normalized "truth" version
def store_canonical(normalized):
    """Store canonical transaction."""
    db.execute("""
        INSERT INTO transactions
        (txn_id, obs_id, date, canonical_merchant, amount,
         currency, category, created_at)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
    """, (generate_id(), normalized['obs_id'],
          normalized['date'], normalized['canonical_merchant'],
          normalized['amount'], normalized['currency'],
          normalized['category'], now()))

# Example stored transaction:
# txn_id: "txn_456"
# obs_id: "obs_123" (link to observation)
# canonical_merchant: "Uber Eats" (clean)
# category: "Food & Dining"
```

---

### **Complete Pipeline Orchestration**

```python
def process_upload(pdf_path, upload_id):
    """
    Complete pipeline after upload.

    Total: ~150 LOC for entire pipeline
    Simple, sequential, no async/queues
    """

    # Stage 1: Parse + Store Observations (~30 LOC)
    observations = parse_and_store(pdf_path, upload_id)
    print(f"âœ“ Extracted {len(observations)} observations")

    # Stage 2: Clustering (~50 LOC)
    clusters = cluster_merchants(observations)
    print(f"âœ“ Identified {len(clusters)} merchant clusters")

    # Stage 3: Normalization (~40 LOC)
    normalized = []
    for obs in observations:
        canonical = normalize(obs, clusters)
        normalized.append(canonical)
    print(f"âœ“ Normalized {len(normalized)} transactions")

    # Stage 4: Store Canonical (~20 LOC)
    for txn in normalized:
        store_canonical(txn)
    print(f"âœ“ Stored {len(normalized)} canonical transactions")

    # Stage 5: Post-processing (~30 LOC)
    detect_transfers(upload_id)
    update_merchant_registry(clusters)
    print(f"âœ“ Pipeline complete")

    return {
        'observations': len(observations),
        'transactions': len(normalized),
        'clusters': len(clusters)
    }
```

---

### **Data Model: Two Stores**

**ObservationStore (Raw Data):**
```sql
CREATE TABLE observations (
    obs_id TEXT PRIMARY KEY,
    upload_id TEXT NOT NULL,
    row_id INTEGER NOT NULL,         -- Row number in PDF (1, 2, 3...)
    date TEXT NOT NULL,              -- ISO: 2022-10-15
    raw_merchant TEXT NOT NULL,      -- "UBER *EATS" (AS-IS from PDF)
    amount REAL NOT NULL,
    currency TEXT NOT NULL,
    created_at TEXT NOT NULL,
    FOREIGN KEY (upload_id) REFERENCES uploads(upload_id)
);

-- Index for querying
CREATE INDEX idx_obs_upload ON observations(upload_id);
CREATE INDEX idx_obs_merchant ON observations(raw_merchant);
```

**CanonicalStore (Truth):**
```sql
CREATE TABLE transactions (
    txn_id TEXT PRIMARY KEY,
    obs_id TEXT NOT NULL,            -- Link to observation
    account_id TEXT NOT NULL,
    upload_id TEXT NOT NULL,
    date TEXT NOT NULL,
    canonical_merchant TEXT NOT NULL, -- "Uber Eats" (normalized)
    amount REAL NOT NULL,
    currency TEXT NOT NULL,
    category TEXT,                   -- "Food & Dining"
    is_transfer BOOLEAN DEFAULT 0,
    transfer_pair_id TEXT,
    notes TEXT,
    created_at TEXT NOT NULL,
    FOREIGN KEY (obs_id) REFERENCES observations(obs_id),
    FOREIGN KEY (account_id) REFERENCES accounts(account_id)
);

-- Indexes for querying
CREATE INDEX idx_txn_date ON transactions(date);
CREATE INDEX idx_txn_merchant ON transactions(canonical_merchant);
CREATE INDEX idx_txn_category ON transactions(category);
CREATE INDEX idx_txn_account ON transactions(account_id);
```

**Why Two Tables:**
1. âœ… **Preserve raw data**: Can always see what PDF actually said
2. âœ… **Re-normalize**: Change rules â†’ re-run pipeline on observations
3. âœ… **Audit trail**: Track what changed from raw to canonical
4. âœ… **UI clean**: Show canonical_merchant ("Uber Eats") not raw ("UBER *EATS")

---

### **Pipeline Complexity Budget**

**Total LOC breakdown:**
```
Stage 1: Parse + ObservationStore    ~30 LOC
Stage 2: Clustering                   ~50 LOC
Stage 3: Normalization                ~40 LOC
Stage 4: CanonicalStore               ~20 LOC
Stage 5: Post-processing              ~30 LOC
Pipeline orchestration                ~30 LOC
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Pipeline:                      ~200 LOC

Plus:
- Parsers (4 Ã— 100 LOC):             400 LOC
- UI (Flask + templates):            500 LOC
- Other features:                    700 LOC
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total V1:                          ~1800 LOC
```

**Remains simple because:**
- âŒ No ML (just string similarity)
- âŒ No async/queues (sequential)
- âŒ No complex abstractions
- âœ… Hardcoded thresholds (80% similarity)
- âœ… Simple regex rules (JSON file)
- âœ… Standard algorithms (Levenshtein distance)

---

### **User Experience (Pipeline Hidden)**

**Darwin sees:**
```
1. Upload BofA_Oct2024.pdf
2. [2 seconds...]
3. âœ“ 48 transactions added

[Click "View Transactions"]

Date         Merchant        Amount
2024-10-31   Uber Eats      -$18.00  â† Clean!
2024-10-30   Starbucks      -$5.50   â† Clean!
```

**Behind the scenes (Darwin doesn't see):**
```
Upload â†’ Parse (48 raw) â†’ ObservationStore
      â†’ Cluster (15 groups) â†’ Normalize (48 canonical)
      â†’ CanonicalStore â†’ UI reads canonical
```

**Principle: Complexity hidden, experience simple** âœ…

---

## ğŸ‘¤ Darwin's Real Context

### **Perfil Personal**
- **UbicaciÃ³n**: USA/MÃ©xico (trabaja remotamente, vive en ambos lugares)
- **SituaciÃ³n financiera**: Multi-paÃ­s (USD + MXN)
- **MotivaciÃ³n**: 2 aÃ±os de statements sin revisar, necesita visibilidad de flujo de dinero
- **Tech comfort**: Developer, prefiere localhost simple sobre SaaS complejo

---

### **Sistema de Cuentas (4 total)**

Darwin tiene un sistema multi-paÃ­s optimizado para minimizar fees de conversiÃ³n:

```python
DARWIN_ACCOUNTS = [
    {
        "id": "bofa_checking",
        "name": "BofA Checking",
        "institution": "Bank of America",
        "currency": "USD",
        "type": "checking",
        "purpose": "Primary income account (USA)",
        "typical_balance": "$5,000-10,000",
        "inflows": "Salary, freelance income (USD)",
        "outflows": "USA expenses, transfers to Wise"
    },
    {
        "id": "apple_card",
        "name": "Apple Card",
        "institution": "Apple/Goldman Sachs",
        "currency": "USD",
        "type": "credit",
        "purpose": "Primary spending (cashback 2-3%)",
        "typical_balance": "-$1,000 to -$2,000 (paid monthly from BofA)",
        "inflows": "Payments from BofA",
        "outflows": "Daily purchases, subscriptions"
    },
    {
        "id": "wise_usd",
        "name": "Wise USD",
        "institution": "Wise",
        "currency": "USD",
        "type": "checking",
        "purpose": "Currency exchange intermediary (low fees)",
        "typical_balance": "$500-1,500",
        "inflows": "Transfers from BofA",
        "outflows": "Conversions to MXN â†’ Scotia"
    },
    {
        "id": "scotia_mxn",
        "name": "Scotia MXN",
        "institution": "Scotiabank Mexico",
        "currency": "MXN",
        "type": "checking",
        "purpose": "Mexico expenses (rent, family, local purchases)",
        "typical_balance": "10,000-20,000 MXN (~$600-1,200 USD)",
        "inflows": "USDâ†’MXN conversions from Wise",
        "outflows": "Mexico rent, groceries, local expenses"
    }
]
```

---

### **Flujo de Dinero Mensual**

**Ingresos (Income):**
```
$4,500-6,000 USD/month â†’ BofA Checking
â”œâ”€ Salary (empleado remoto)
â””â”€ Freelance projects (ocasional)
```

**Flujo Principal (Main Flow):**
```
BofA Checking ($5,000)
    â†“
    â”œâ”€â†’ Apple Card Payment ($1,500-2,000)  [USA expenses]
    â”‚   â”œâ”€ Food & Dining: $800-1,000
    â”‚   â”œâ”€ Transportation: $300-400 (Uber)
    â”‚   â”œâ”€ Shopping: $400-600
    â”‚   â””â”€ Subscriptions: $150 (Netflix, Spotify, etc)
    â”‚
    â”œâ”€â†’ Direct USA expenses from BofA ($500-1,000)
    â”‚   â””â”€ Utilities, insurance, misc
    â”‚
    â””â”€â†’ Transfer to Wise USD ($500-1,000)
            â†“
        Convert USDâ†’MXN (better rate than bank)
            â†“
        Transfer to Scotia MXN ($300-500 â†’ ~6,000-10,000 MXN)
            â†“
        Mexico expenses:
            â”œâ”€ Rent: ~8,000 MXN (~$400)
            â”œâ”€ Groceries: ~2,000 MXN (~$100)
            â”œâ”€ Family support: varies
            â””â”€ Local purchases: varies
```

**Total Monthly Flow:**
- **Income**: $4,500-6,000 USD
- **USA Expenses**: ~$2,500-3,000 USD (via Apple Card + BofA direct)
- **Mexico Expenses**: ~$500-800 USD (via Wiseâ†’Scotia)
- **Net**: ~$1,000-2,500 USD saved/invested

---

### **Por QuÃ© Este Setup**

**1. BofA (Primary):**
- Cuenta principal en USA
- Recibe todos los ingresos
- Familiarity (cuenta desde hace aÃ±os)
- Network de ATMs en USA

**2. Apple Card (Credit):**
- Cashback 2-3% en compras
- No foreign transaction fees
- Apple ecosystem integration
- Build credit score

**3. Wise (Currency Exchange):**
- **Problema que resuelve**: Banks charge 3-4% for USDâ†’MXN
- **SoluciÃ³n Wise**: 0.5-1% fee (save $20-40 per transfer)
- Mid-market exchange rate (no markup)
- Fast transfers (1-2 days)

**4. Scotia MXN (Mexico):**
- Local bank account required for Mexico
- Rent payments (landlord requires local transfer)
- Local ATM withdrawals without fees
- Family support (can transfer to relatives)

---

### **Pain Points Darwin Quiere Resolver**

**1. Visibilidad de Flujo:**
- "Â¿A dÃ³nde va mi dinero realmente?"
- "Â¿Gasto mÃ¡s ahora que hace 2 aÃ±os?"
- "Â¿CuÃ¡nto va a USA vs MÃ©xico?"

**2. Transfer Tracking:**
- "Â¿Esa transferencia BofAâ†’Wise corresponde con Wiseâ†’Scotia?"
- "Â¿Estoy perdiendo dinero en conversiones?"

**3. Merchant Normalization:**
- "UBER *EATS", "UberEATS", "Uber Eats" â†’ should all be "Uber Eats"
- "STARBUCKS STORE 1234" â†’ should be "Starbucks"

**4. Currency Clarity:**
- "Â¿CuÃ¡nto gasto total en USD equivalente?"
- "$1,000 USD transferido = Â¿cuÃ¡ntos MXN recibidos?"

**5. Historical Analysis:**
- Tiene 2 aÃ±os de PDFs sin revisar
- Quiere cargar todo de una vez
- Ver trends (Â¿gasto mÃ¡s en 2024 que 2022?)

---

### **Por QuÃ© V1 Necesita Estas Features**

**Upload & Parse:**
- Darwin tiene 96 PDFs acumulados (24 meses Ã— 4 cuentas)
- Necesita cargar todos rÃ¡pidamente (timeline continuo)

**Normalization:**
- Darwin ve "UBER *EATS" en BofA, "Uber Eats" en Apple Card
- Quiere entender: "Â¿CuÃ¡nto gastÃ© en Uber total?"

**Transfer Detection:**
- Darwin mueve $500-1,000/mes entre cuentas
- Sin detecciÃ³n: aparecen como +$500 (income) y -$500 (expense) â†’ infla totales
- Con detecciÃ³n: se marcan como transfers â†’ totales correctos

**Currency Conversion:**
- Darwin necesita ver: "GastÃ© $2,800 total (incluyendo MXN convertido)"
- Scotia muestra "8,000 MXN" â†’ convertir a "$400 USD" para dashboard

**Dashboard:**
- "GastÃ© $3,200 en Oct 2024 vs $2,800 en Oct 2022" (+14%)
- "Food & Dining aumentÃ³ $150/mes desde 2022"
- "Transfers a MÃ©xico promedio: $650/mes"

---

### **Volumen de Datos**
- **Transacciones/mes**: ~500 (125 por cuenta promedio)
- **Periodo histÃ³rico**: 2 aÃ±os (Oct 2022 - Oct 2024)
- **Total transacciones**: ~12,000 (2 aÃ±os Ã— 500/mes)
- **Statements/mes**: 4 (uno por cuenta)
- **Total statements a cargar**: ~96 (24 meses Ã— 4 cuentas)

### **Uso TÃ­pico**

**Semana 1 (Carga inicial):**
- Darwin sube 96 PDFs (todos sus statements de 2 aÃ±os)
- ~12,000 transacciones cargadas
- Normalization detecta ~200 merchants Ãºnicos
- Transfer detection encuentra ~150 transfers

**Semana 2-4 (ExploraciÃ³n):**
- Darwin busca "Uber" â†’ 150 matches (2022-2024)
- Filtra "Food & Dining" â†’ 3,500 transacciones
- Revisa dashboard â†’ "Gastas $200 mÃ¡s/mes que hace 2 aÃ±os"
- Categoriza ~50 transacciones uncategorized

**Mes 2+ (Uso continuo):**
- Darwin recibe nuevos statements (4 PDFs/mes)
- Sube los 4 PDFs
- Se agregan al timeline existente
- Dashboard se actualiza automÃ¡ticamente
- ContinÃºa usando el app normalmente

---

## ğŸ¯ Scope V1: QuÃ© Incluye

### **âœ… Features Incluidas**

#### **1. Upload & Parse (Critical)**
- Upload PDF via web form
- Auto-detect banco (BofA, Apple Card, Wise, Scotia) basado en layout
- Parse statement â†’ extract raw observations (AS-IS)
- Store en ObservationStore con fecha original del statement
- Duplicate detection (hash SHA256 del PDF)
- Handle corrupted PDFs gracefully

#### **2. Truth Construction Pipeline (Critical)**
- **ObservationStore**: Store raw data exactly as extracted from PDF
- **Clustering**: Group similar merchant variants (string similarity, no ML)
- **Normalization**: Apply regex rules + clusters â†’ canonical names
- **CanonicalStore**: Store clean "truth" version for UI
- **Pipeline automÃ¡tico**: Runs after every upload (sequential, simple)

#### **3. Transaction Management (Critical)**
- List todas las transacciones from CanonicalStore (TODO el timeline)
- Filtros: date range, merchant, amount range, category, account
- Search por texto (busca en canonical merchant name)
- Transaction detail view (ver raw observation + canonical transaction)
- PaginaciÃ³n (50 txns/page)

#### **4. Normalization & Clustering (Critical)**
- Merchant clustering: String similarity (Levenshtein distance, 80% threshold)
- Normalization rules: Regex patterns en JSON file
- Rule priority: Higher priority wins
- Manual override: Darwin puede editar canonical name
- Auto-categorization basada en normalized merchant

#### **5. Accounts & Merchants (Important)**
- List Darwin's 4 accounts
- View balance per account
- List all known merchants
- Add/edit merchant info (canonical name, aliases, default category)

#### **6. Intelligence (Important)**
- Transfer detection automÃ¡tica (matching debit/credit, Â±3 days, same amount)
- Currency conversion (MXN â†’ USD usando rate hardcoded)
- Categorization (10-15 categories: Food, Transport, etc)
- Manual category assignment

#### **7. Dashboard (Important)**
- Total balance (across all accounts, converted to USD)
- Spending by category (pie chart, last 30 days)
- Monthly trend (line chart, todos los meses disponibles)
- Top merchants (top 10 by spending)

#### **8. UI (Critical)**
- Web interface (Flask/FastAPI)
- 5 pÃ¡ginas principales:
  1. Upload (form + recent uploads list)
  2. Transactions (list + filters)
  3. Transaction Detail (single transaction view)
  4. Accounts & Merchants (registry views)
  5. Dashboard (summary + charts)
- Responsive (funciona en desktop, no mÃ³vil optimizado)

---

### **âŒ Fuera de Scope V1**

- âŒ API pÃºblica (REST endpoints para terceros)
- âŒ Multi-user / authentication (solo Darwin usa, localhost)
- âŒ Real-time bank sync (no plaid, no OAuth)
- âŒ Mobile app nativa
- âŒ Budgets / forecasting avanzado
- âŒ Split transactions (1 txn â†’ mÃºltiples categories)
- âŒ Recurring transaction detection
- âŒ Receipt scanning / OCR
- âŒ Export to CSV/QBO
- âŒ Tax reporting detallado
- âŒ Investment tracking
- âŒ Loans/mortgages
- âŒ ProvenanceLedger / audit trails detallados
- âŒ Bitemporal queries

---

## ğŸ—ï¸ Technical Constraints

### **Architecture**
```
finance-app-v1/
â”œâ”€â”€ parsers/              # 4 archivos (bofa.py, apple_card.py, wise.py, scotia.py)
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ upload.py        # Upload handler
â”‚   â”œâ”€â”€ pipeline.py      # Truth construction pipeline (cluster + normalize)
â”‚   â”œâ”€â”€ observations.py  # ObservationStore operations
â”‚   â”œâ”€â”€ transactions.py  # CanonicalStore operations
â”‚   â”œâ”€â”€ accounts.py      # Account management
â”‚   â”œâ”€â”€ merchants.py     # Merchant registry
â”‚   â”œâ”€â”€ transfers.py     # Transfer detection
â”‚   â”œâ”€â”€ currency.py      # Currency conversion
â”‚   â””â”€â”€ db.py            # SQLite helpers
â”œâ”€â”€ ui/                   # Flask/FastAPI + templates + static
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ finance.db       # SQLite database (2 main tables: observations + transactions)
â”‚   â”œâ”€â”€ uploads/         # PDF files
â”‚   â””â”€â”€ rules.json       # Normalization rules
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_db.py       # Create schema (observations + transactions tables)
â”‚   â””â”€â”€ seed_data.py     # Darwin's 4 accounts + initial rules
â””â”€â”€ main.py               # Entry point

~1800 LOC total
```

### **Tech Stack**
- **Language**: Python 3.10+
- **Web**: Flask or FastAPI (tu elecciÃ³n)
- **DB**: SQLite (single file: `data/finance.db`)
- **PDF parsing**: pdfplumber
- **No dependencies pesadas**: No pandas, no ML libs, no Redis

### **Data Model (SQLite)**

**Tables (6 principales):**
1. **accounts** (4 rows - Darwin's accounts)
2. **observations** (12k+ rows - raw data from PDFs)
3. **transactions** (12k+ rows - canonical/normalized data)
4. **uploads** (96+ rows - tracking de PDFs subidos)
5. **merchants** (200+ rows - counterparty registry)
6. **normalization_rules** (50+ rows - regex patterns)

**Schema completo:**
```sql
-- accounts: Darwin's 4 cuentas
CREATE TABLE accounts (
    account_id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    institution TEXT NOT NULL,
    currency TEXT NOT NULL,
    type TEXT NOT NULL
);

-- observations: Raw data (AS-IS from PDF)
CREATE TABLE observations (
    obs_id TEXT PRIMARY KEY,
    upload_id TEXT NOT NULL,
    row_id INTEGER NOT NULL,         -- Row number in PDF (1, 2, 3...)
    date TEXT NOT NULL,              -- ISO: 2022-10-15
    raw_merchant TEXT NOT NULL,      -- "UBER *EATS" (exactly as in PDF)
    amount REAL NOT NULL,
    currency TEXT NOT NULL,
    created_at TEXT NOT NULL,
    FOREIGN KEY (upload_id) REFERENCES uploads(upload_id)
);

CREATE INDEX idx_obs_upload ON observations(upload_id);
CREATE INDEX idx_obs_merchant ON observations(raw_merchant);

-- transactions: Canonical data (normalized/clean)
CREATE TABLE transactions (
    txn_id TEXT PRIMARY KEY,
    obs_id TEXT NOT NULL,            -- Link to observation
    account_id TEXT NOT NULL,
    upload_id TEXT NOT NULL,
    date TEXT NOT NULL,              -- ISO: 2022-10-15
    canonical_merchant TEXT NOT NULL, -- "Uber Eats" (normalized)
    amount REAL NOT NULL,
    currency TEXT NOT NULL,
    category TEXT,                   -- "Food & Dining"
    is_transfer BOOLEAN DEFAULT 0,
    transfer_pair_id TEXT,
    notes TEXT,
    created_at TEXT NOT NULL,
    FOREIGN KEY (obs_id) REFERENCES observations(obs_id),
    FOREIGN KEY (account_id) REFERENCES accounts(account_id)
);

CREATE INDEX idx_txn_date ON transactions(date);
CREATE INDEX idx_txn_merchant ON transactions(canonical_merchant);
CREATE INDEX idx_txn_category ON transactions(category);
CREATE INDEX idx_txn_account ON transactions(account_id);

-- uploads: Tracking de PDFs
CREATE TABLE uploads (
    upload_id TEXT PRIMARY KEY,
    file_hash TEXT UNIQUE NOT NULL,  -- SHA256
    file_name TEXT NOT NULL,
    bank TEXT NOT NULL,              -- "bofa", "apple_card", etc
    upload_date TEXT NOT NULL,
    obs_count INTEGER NOT NULL,      -- Observations extracted
    txn_count INTEGER NOT NULL       -- Transactions created
);

-- merchants: Counterparty registry
CREATE TABLE merchants (
    merchant_id TEXT PRIMARY KEY,
    canonical_name TEXT NOT NULL,
    aliases TEXT,                    -- JSON array: ["UBER *EATS", "UberEATS"]
    category TEXT,
    notes TEXT
);

-- normalization_rules: Regex patterns
CREATE TABLE normalization_rules (
    rule_id TEXT PRIMARY KEY,
    pattern TEXT NOT NULL,           -- "UBER.*EATS"
    canonical_merchant TEXT NOT NULL,
    category TEXT,
    priority INTEGER DEFAULT 1       -- Higher priority wins
);
```

**Key Difference:**
- **observations**: Raw data preserved (what PDF actually said)
- **transactions**: Clean data for UI (normalized merchant names)
- Link: `transactions.obs_id â†’ observations.obs_id`

---

## ğŸ“¦ Deliverables: QuÃ© Debes Crear

### **Estructura de Carpeta Nueva**
```
/Users/darwinborges/finance-app-v1-docs/
â”œâ”€â”€ README.md                           # Overview + how to use docs
â”œâ”€â”€ 0-scope.md                          # Scope detallado (incluye/no incluye)
â”œâ”€â”€ 1-architecture.md                   # Arquitectura V1 completa
â”œâ”€â”€ 2-data-model.md                     # SQLite schema completo
â”œâ”€â”€ 3-tech-stack.md                     # Tech decisions + justifications
â”‚
â”œâ”€â”€ batches/                            # 10 batches de trabajo
â”‚   â”œâ”€â”€ batch-1-foundation.md          # Setup + DB (2 tables) + config
â”‚   â”œâ”€â”€ batch-2-upload-parse.md        # Upload + 4 parsers + ObservationStore
â”‚   â”œâ”€â”€ batch-3-pipeline.md            # Truth construction (Cluster â†’ Normalize â†’ Canonical)
â”‚   â”œâ”€â”€ batch-4-normalization.md       # Normalization rules + merchant registry
â”‚   â”œâ”€â”€ batch-5-registry.md            # Accounts + Merchants management
â”‚   â”œâ”€â”€ batch-6-intelligence.md        # Transfers + Currency + Categories
â”‚   â”œâ”€â”€ batch-7-ui-upload.md           # Upload UI
â”‚   â”œâ”€â”€ batch-8-ui-transactions.md     # Transaction list + filters
â”‚   â”œâ”€â”€ batch-9-ui-detail.md           # Transaction detail view (raw + canonical)
â”‚   â””â”€â”€ batch-10-ui-dashboard.md       # Dashboard + charts
â”‚
â”œâ”€â”€ user-flows/                         # 5 flujos principales
â”‚   â”œâ”€â”€ flow-1-timeline-continuo.md    # Carga inicial + uso continuo (UNIFICADO)
â”‚   â”œâ”€â”€ flow-2-search-filter.md        # Buscar/filtrar en timeline
â”‚   â”œâ”€â”€ flow-3-categorization.md       # Asignar categorÃ­as
â”‚   â”œâ”€â”€ flow-4-transfers.md            # Revisar transfers detectados
â”‚   â””â”€â”€ flow-5-dashboard.md            # Monthly review
â”‚
â”œâ”€â”€ technical/                          # Specs tÃ©cnicos detallados
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”œâ”€â”€ bofa-parser.md             # BofA parser (layout, regex, edge cases)
â”‚   â”‚   â”œâ”€â”€ apple-card-parser.md       # Apple Card parser
â”‚   â”‚   â”œâ”€â”€ wise-parser.md             # Wise parser
â”‚   â”‚   â””â”€â”€ scotia-parser.md           # Scotia parser (MXN)
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ pipeline-overview.md       # Complete pipeline flow
â”‚   â”‚   â”œâ”€â”€ clustering-algorithm.md    # String similarity (Levenshtein)
â”‚   â”‚   â”œâ”€â”€ normalization-engine.md    # Rules + clusters â†’ canonical
â”‚   â”‚   â””â”€â”€ observation-vs-canonical.md # Why two stores
â”‚   â”œâ”€â”€ auto-detection.md              # CÃ³mo auto-detectar banco del PDF
â”‚   â”œâ”€â”€ normalization-rules.md         # Regex patterns + priority
â”‚   â”œâ”€â”€ transfer-detection.md          # Transfer matching algorithm
â”‚   â”œâ”€â”€ currency-conversion.md         # MXN â†” USD conversion
â”‚   â””â”€â”€ duplicate-handling.md          # Duplicate PDF detection
â”‚
â””â”€â”€ storytelling/
    â”œâ”€â”€ darwin-complete-story.md        # Historia completa (timeline continuo)
    â””â”€â”€ edge-cases.md                   # 20+ edge cases que V1 debe manejar
```

---

## ğŸ“ Formato de Cada Documento

### **Batch Documents (9 archivos)**

Cada batch debe incluir:

```markdown
# Batch N: [Nombre]

## Overview
- **Purpose**: Para quÃ© sirve este batch
- **Dependencies**: QuÃ© batches previos necesita completados
- **Estimated LOC**: ~200 LOC
- **Estimated Time**: 3-4 horas

## Components
Lista de archivos/mÃ³dulos a crear:
- `app/upload.py` - Upload handler
- `parsers/bofa.py` - BofA parser
- ...

## Detailed Specifications

### Component 1: upload.py
**Purpose**: Handle PDF upload, detect bank, trigger parsing

**Functions:**
```python
def upload_statement(pdf_file) -> dict:
    """
    Upload PDF statement.

    Args:
        pdf_file: Uploaded file object

    Returns:
        {
            "upload_id": "upl_abc123",
            "bank": "bofa",
            "txn_count": 45,
            "status": "success"
        }

    Edge cases:
    - Duplicate PDF (same hash) â†’ return existing upload_id
    - Corrupted PDF â†’ return error with details
    - Unknown bank â†’ return error "Unsupported bank"
    """
    # 1. Calculate file hash (SHA256)
    # 2. Check if already uploaded
    # 3. Detect bank from PDF layout
    # 4. Call appropriate parser
    # 5. Store transactions in DB
    # 6. Return upload summary
```

[Spec detallada para cada funciÃ³n]

## Acceptance Criteria
- [ ] Can upload BofA PDF â†’ 45 transactions extracted
- [ ] Can upload Apple Card PDF â†’ 52 transactions extracted
- [ ] Duplicate PDF rejected with clear message
- [ ] Corrupted PDF returns error (not crash)
- [ ] All tests pass

## Testing
**Unit tests:**
- `test_upload_valid_pdf()` - Upload BofA statement
- `test_upload_duplicate()` - Upload same PDF twice
- `test_upload_corrupted()` - Upload invalid PDF

**Integration tests:**
- Upload 4 different banks â†’ all succeed
- Upload 96 PDFs (Darwin's 2 years) â†’ all succeed

## Edge Cases
1. **Duplicate upload**: Hash exists â†’ return existing upload_id, don't re-parse
2. **Corrupted PDF**: pdfplumber fails â†’ catch exception, return friendly error
3. **Unknown bank**: No parser matches â†’ return error with "Please contact support"
```

---

### **User Flow Documents (5 archivos)**

Cada flow debe incluir:

```markdown
# User Flow: [Nombre]

## Context
**User**: Darwin
**Goal**: [Objetivo del usuario]
**Preconditions**: [Estado inicial]

## Story

### Part 1: [TÃ­tulo]
**Narrative:**
Darwin [acciÃ³n]...

**Steps:**
1. Darwin opens http://localhost:5000/upload
2. Clicks "Choose File"
3. Selects `BofA_Oct2022.pdf` from ~/Downloads
4. Clicks "Upload"

**System behavior:**
- Server receives PDF
- Calculates hash: `sha256_abc123...`
- Checks uploads table â†’ hash not found (first upload)
- Detects bank: "bofa" (from PDF layout)
- Calls `parsers.bofa.parse()`
- Extracts 45 transactions
- Inserts to transactions table
- Creates upload record

**User sees:**
```
âœ“ Upload successful
  File: BofA_Oct2022.pdf
  Bank: Bank of America
  Transactions: 45
  Period: Oct 1-31, 2022
```

[Continuar con mÃ¡s parts del flow]

## Edge Cases Encountered
1. Darwin uploads same PDF twice
2. Darwin uploads corrupted PDF
3. Darwin uploads statement from unsupported bank

## UI Mockups
[DescripciÃ³n de wireframes/screenshots]

## Success Criteria
- [ ] Darwin can complete entire flow without errors
- [ ] All transactions appear in list
- [ ] Search works across all uploaded statements
- [ ] Dashboard updates with new data
```

---

### **Technical Specs (8 archivos)**

Formato de parser specs:

```markdown
# BofA Parser Specification

## Bank Information
- **Institution**: Bank of America
- **Statement Type**: Checking Account
- **Format**: PDF (text-based)
- **Layout**: Table format, 3 columns (Date, Description, Amount)

## PDF Layout Example
```
BANK OF AMERICA
Checking Account Statement
Account: ...1234

Date        Description              Amount
10/01      UBER *EATS               -$15.00
10/02      DEPOSIT PAYROLL        +$2,500.00
10/03      STARBUCKS STORE 1234    -$5.50
...
```

## Parsing Strategy

### Detection
How to detect this is a BofA statement:
```python
def is_bofa_statement(text):
    """Returns True if PDF is BofA checking statement."""
    indicators = [
        "BANK OF AMERICA" in text,
        "Checking Account Statement" in text,
        re.search(r"Account:.*\d{4}", text)
    ]
    return all(indicators)
```

### Extraction
```python
def parse_bofa_statement(pdf_path):
    """
    Extract transactions from BofA checking statement.

    Returns:
        List[dict]: [
            {
                "date": "2022-10-01",
                "merchant": "UBER *EATS",
                "amount": -15.00,
                "currency": "USD"
            },
            ...
        ]
    """
    # Implementation details
    # 1. Open PDF with pdfplumber
    # 2. Extract text from all pages
    # 3. Find transaction table
    # 4. Apply regex pattern
    # 5. Parse each transaction
    # 6. Return list
```

## Edge Cases
1. **Multi-page statements**: Iterate all pages
2. **Pending transactions**: Skip (not posted yet)
3. **Foreign transactions**: May include "FOREIGN TRANSACTION FEE" line
4. **Layout changes**: BofA changes format occasionally

## Test Data
Include 3 sample statements:
- `bofa_oct2022.pdf` - Normal statement (45 txns)
- `bofa_dec2023.pdf` - Holiday spending (120 txns)
- `bofa_jan2024.pdf` - Layout change (new format)

## Validation
After parsing, verify:
- [ ] All dates are valid ISO format
- [ ] All amounts are floats
- [ ] Currency is "USD"
- [ ] No duplicate transactions within same statement
```

---

### **Storytelling Document (darwin-complete-story.md)**

Narrativa completa de Darwin usando el app:

```markdown
# Darwin's Complete Story: Finance App V1

## Prologue: The Problem
Darwin has been downloading bank statements for 2 years (Oct 2022 - Oct 2024).
He has 96 PDFs sitting in ~/Downloads, never opened.

He wants to:
- Know his total spending last year
- Find all Uber rides in 2023
- See if he's spending more or less than before
- Track where his money goes

Excel is too tedious. Mint.com is bloated. He wants something simple but complete.

---

## Chapter 1: First Contact (Week 1, Day 1)

**Monday, November 4, 2024 - 8:00 PM**

Darwin opens terminal:
```bash
cd ~/finance-app-v1
python main.py
```

Browser opens: http://localhost:5000

He sees:
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     Finance App V1                 â•‘
â•‘     Upload your first statement    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[Choose File]  [Upload]
```

Darwin drags `BofA_Oct2024.pdf` from ~/Downloads.

Clicks "Upload".

**2 seconds later:**
```
âœ“ Upload successful
  File: BofA_Oct2024.pdf
  Bank: Bank of America
  Transactions: 48
  Period: Oct 1-31, 2024

[View Transactions]
```

Darwin clicks "View Transactions".

He sees a table:
```
Date         Account        Merchant          Amount
2024-10-31   BofA Checking  UBER *EATS       -$18.00
2024-10-31   BofA Checking  SPOTIFY          -$10.99
2024-10-30   BofA Checking  WHOLE FOODS      -$87.34
...
```

"It works!" Darwin thinks.

---

## Chapter 2: The Historical Load (Week 1, Days 2-3)

Darwin realizes: "I have 2 years of statements. Let me load them all."

He opens ~/Downloads, selects all BofA statements:
- BofA_Oct2022.pdf
- BofA_Nov2022.pdf
- ...
- BofA_Sep2024.pdf

24 files total.

**Upload process:**
- First file: 2 seconds
- Second file: 2 seconds
- ...
- 24th file: 2 seconds

Total time: 48 seconds.

Darwin refreshes transaction list.

Now he sees:
```
Showing 1-50 of 1,127 transactions (Oct 2022 - Oct 2024)

Date         Account        Merchant          Amount
2024-10-31   BofA Checking  UBER *EATS       -$18.00
...
2022-10-01   BofA Checking  STARBUCKS        -$4.50
```

"Wow. 2 years of data in one view."

---

[Continuar con mÃ¡s capÃ­tulos: subir otros bancos, exploraciÃ³n, categorizaciÃ³n, etc]

## Epilogue: Daily Use (Month 2+)

November 30, 2024.

Darwin receives email: "Your October statement is ready".

He downloads BofA_Nov2024.pdf.

Opens app. Drags file. Clicks upload.

2 seconds.

51 new transactions added.

Dashboard updates automatically:
```
November 2024 Spending: $2,847.23 (-8% vs October)
```

"This is so simple," Darwin thinks. "Why didn't I build this 2 years ago?"

---

## Lessons Learned

1. **Timeline continuo works**: No distinction between loading old statements vs new ones
2. **Auto-detection is crucial**: No dropdowns, just upload
3. **Pipeline is invisible**: Darwin sees clean data, doesn't know about clustering/normalization
4. **Normalization saves time**: "UBER *EATS" â†’ "Uber Eats" automatically
5. **Transfer detection is magic**: "Wait, these $1000 transactions match!"
6. **Two stores = power**: Can always see raw data, can re-normalize anytime
7. **Simple is powerful**: ~1800 LOC, simple algorithms, works perfectly

**Darwin is happy. V1 is complete.**
```

---

## âœ… Success Criteria

### **Documentation Quality**
- [ ] Cada batch es self-contained (puede implementarse independientemente)
- [ ] Cada spec incluye edge cases concretos
- [ ] User flows son narrativos (story-driven, no solo bullets)
- [ ] Technical specs incluyen cÃ³digo de ejemplo (pseudo-code OK)
- [ ] Darwin's story es completa (intro â†’ daily use)

### **Completeness**
- [ ] 10 batches documentados (foundation â†’ pipeline â†’ dashboard)
- [ ] 5 user flows completos
- [ ] 4 parser specs detallados
- [ ] 4 pipeline specs (overview, clustering, normalization, obs vs canonical)
- [ ] Normalization rules, transfers, currency specs
- [ ] Edge cases document con 20+ casos

### **Clarity**
- [ ] Alguien sin contexto puede leer docs y entender quÃ© hacer
- [ ] No ambigÃ¼edad sobre quÃ© estÃ¡ in/out of scope
- [ ] Ejemplos concretos (no abstractos)
- [ ] Hardcoded estÃ¡ explÃ­citamente OK (donde aplique)

### **Alignment con Vision**
- [ ] Timeline continuo estÃ¡ presente en todos los flows
- [ ] No separaciÃ³n "histÃ³rico vs diario"
- [ ] Simple pero completo (no simplificado al punto de inÃºtil)
- [ ] Example-first approach visible (hardcoded â†’ refactor later)

---

## ğŸš« Anti-Patterns: QuÃ© NO Hacer

### **1. NO Pre-diseÃ±ar Abstracciones**
âŒ **Wrong:**
```markdown
# Batch 2: Upload

First, create abstract StorageEngine interface:
- store(content) â†’ ref
- retrieve(ref) â†’ content

Then implement LocalFileSystemBackend...
```

âœ… **Correct:**
```markdown
# Batch 2: Upload

Create simple upload handler:
```python
def upload_statement(pdf_file):
    # Save to ~/uploads/ directly (hardcoded path OK)
    path = f"~/uploads/{hash_value}.pdf"
    with open(path, 'wb') as f:
        f.write(pdf_file.read())
```

No abstractions. No interfaces. Just make it work.
```

---

### **2. NO Separar "Setup" de "Daily Use"**
âŒ **Wrong:**
```markdown
# Flow 1: Initial Setup (historical load)
# Flow 2: Daily Use (new statements)
```

âœ… **Correct:**
```markdown
# Flow 1: Timeline Continuo (carga inicial + uso diario es EL MISMO FLUJO)
```

---

### **3. NO Sobre-generalizar Parsers**
âŒ **Wrong:**
```python
class UniversalBankParser:
    def parse(self, pdf, config):
        # Generic parser for ANY bank
        ...
```

âœ… **Correct:**
```python
def parse_bofa(pdf_path):
    # Hardcoded regex for BofA
    pattern = r'(\d{2}/\d{2})\s+(.+?)\s+(-?\$[\d,]+\.\d{2})'
    ...

def parse_apple_card(pdf_path):
    # Different hardcoded regex for Apple Card
    pattern = r'(\w{3}\s\d{2})\s+(.+?)\s+\$(\d+\.\d{2})'
    ...
```

---

### **4. NO Documentar Abstracciones que No Existen**
âŒ **Wrong:**
```markdown
V1 uses these universal primitives:
- StorageEngine (from truth-construction system)
- ProvenanceLedger (from audit system)
- ObservationStore (from extraction system)
```

âœ… **Correct:**
```markdown
V1 uses:
- SQLite directly (transactions table)
- Local filesystem (~/uploads/ folder)
- Hardcoded logic (no abstraction layers)
```

---

### **5. NO Complexity Bleeding**
âŒ **Wrong:**
```html
<!-- User sees internal states -->
Status: queued_for_parse â†’ parsing â†’ parsed
```

âœ… **Correct:**
```html
<!-- User sees simple labels -->
Status: Processing... â†’ Ready
```

---

## ğŸ“š Knowledge Base: Relevant Context from Previous Work

### **From 23 Verticals (usar como referencia, NO copiar)**

**Upload Flow (1.1):**
- Duplicate detection via SHA256 hash
- Error handling (corrupted PDF, unsupported format)
- Multi-file upload (Darwin uploads 96 PDFs)

**Extraction (1.2):**
- Parser per bank (different layouts)
- Extract raw observations (date, merchant, amount)
- Handle 0 transactions (empty statement)

**Normalization (1.3):**
- Merchant name normalization ("UBER *EATS" â†’ "Uber Eats")
- Rule-based (regex patterns)
- Manual override capability

**Transaction List (2.1):**
- Filtros: date range, merchant, amount, category, account
- Search full-text en merchant name
- Pagination (50 per page)

**Dashboard (2.3):**
- Balance across accounts
- Spending by category (pie chart)
- Monthly trend (line chart)
- Top merchants (top 10)

**Account Registry (3.1):**
- CRUD for accounts
- Balance calculation
- Currency support (USD, MXN)

**Counterparty Registry (3.2):**
- Merchant list
- Aliases (multiple names â†’ canonical name)
- Default category per merchant

**Relationships (3.5):**
- Transfer detection (matching debit/credit)
- Criteria: same amount, opposite sign, Â±3 days, different accounts

**Currency (3.6):**
- Multi-currency support (USD, MXN)
- Conversion to base currency (hardcoded rate OK for V1)

**Edge Cases (from storytelling):**
- Duplicate upload â†’ reject with message
- Corrupted PDF â†’ error but don't crash
- Empty statement (0 transactions) â†’ success with warning
- Layout changes â†’ parser needs update
- Foreign transaction fees â†’ separate line item
- Pending transactions â†’ skip (not yet posted)

---

### **Darwin's Real Usage Patterns**

**Monthly Spending:**
- Food & Dining: $800-1000
- Transportation: $300-400 (mostly Uber)
- Shopping: $400-600
- Subscriptions: $150 (Netflix, Spotify, etc)
- Total: $2,500-3,000/month

**Common Merchants (top 20):**
- Uber / Uber Eats (200+ transactions/year)
- Starbucks (150+ transactions/year)
- Whole Foods (100+ transactions/year)
- Amazon (80+ transactions/year)
- Netflix, Spotify, Apple Music (recurring)

**Transfer Patterns:**
- BofA â†’ Wise USD (monthly, $500-1000)
- Wise USD â†’ Scotia MXN (monthly, $300-500)
- Apple Card payment from BofA (monthly, $1000-2000)

**Edge Cases Darwin Encounters:**
- Uploads wrong file (non-PDF) â†’ error
- Uploads statement twice â†’ duplicate detected
- PDF from unknown bank â†’ unsupported error
- Statement has layout change â†’ parser fails (needs update)

---

## ğŸ¯ Final Checklist Before You Start

- [ ] Entendido: Timeline continuo (NO separaciÃ³n histÃ³rico/diario)
- [ ] Entendido: Simple pero completo (~1800 LOC, todas las features + pipeline)
- [ ] Entendido: Truth Construction Pipeline (Observe â†’ Cluster â†’ Normalize â†’ Canonical)
- [ ] Entendido: Dos stores (observations = raw, transactions = canonical)
- [ ] Entendido: Clustering simple (string similarity, no ML, ~50 LOC)
- [ ] Entendido: Hardcoded OK (no pre-diseÃ±ar abstracciones)
- [ ] Entendido: Darwin tiene 4 cuentas, 2 aÃ±os de historia
- [ ] Entendido: 10 batches + 5 flows + technical specs (incluye pipeline) + storytelling
- [ ] Entendido: NO copiar abstracciones de /Description/
- [ ] Entendido: Example-first (V1 hardcoded, V2 abstraÃ­do despuÃ©s)

---

## ğŸš€ Getting Started

### **Step 1: Create New Folder**
```bash
mkdir /Users/darwinborges/finance-app-v1-docs
cd /Users/darwinborges/finance-app-v1-docs
```

### **Step 2: Start with Core Documents**
1. README.md (overview + table of contents)
2. 0-scope.md (in/out scope detallado)
3. 1-architecture.md (arquitectura V1)
4. 2-data-model.md (SQLite schema)

### **Step 3: Batches (en orden)**
1. batch-1-foundation.md
2. batch-2-upload-parse.md
3. ... (continuar en orden)

### **Step 4: User Flows**
1. flow-1-timeline-continuo.md (ESTE ES EL MÃS IMPORTANTE)
2. ... (continuar)

### **Step 5: Technical Specs**
1. parsers/bofa-parser.md
2. ... (continuar)

### **Step 6: Storytelling**
1. darwin-complete-story.md (narrativa completa)

---

## ğŸ“ Questions?

Si durante el trabajo necesitas clarificaciÃ³n:

**Pregunta 1: "Â¿Debo pre-diseÃ±ar esta abstracciÃ³n?"**
â†’ NO. Hardcoded primero. Abstraer en V2.

**Pregunta 2: "Â¿Esto estÃ¡ in/out of scope?"**
â†’ Checa secciÃ³n "Scope V1" arriba.

**Pregunta 3: "Â¿CÃ³mo manejo este edge case?"**
â†’ Busca en "Knowledge Base" o inventa soluciÃ³n simple.

**Pregunta 4: "Â¿Separo 'setup inicial' de 'uso diario'?"**
â†’ NO. Timeline continuo. UN SOLO FLUJO.

**Pregunta 5: "Â¿CuÃ¡nto detalle incluir en specs?"**
â†’ Suficiente para que alguien pueda implementar sin preguntar.

---

## âœ… You're Ready

Ahora tienes:
- âœ… Vision clara (timeline continuo, simple pero completo)
- âœ… Pipeline completo (Observe â†’ Cluster â†’ Normalize â†’ Canonical)
- âœ… Scope definido (quÃ© incluir, quÃ© no, clustering incluido)
- âœ… Methodology (example-first, hardcoded OK, ~1800 LOC)
- âœ… Darwin's context (4 cuentas, 2 aÃ±os, uso real)
- âœ… Deliverables (10 batches + 5 flows + pipeline specs + storytelling)
- âœ… Success criteria (quÃ© hace buen trabajo)
- âœ… Anti-patterns (quÃ© evitar)
- âœ… Knowledge base (de 23 verticals previos)
- âœ… Data model (observations + transactions, dos stores)

**Important Reminders:**
- Pipeline adds ~200 LOC but remains simple (no ML, no async, sequential)
- Clustering = string similarity (Levenshtein, 80% threshold)
- Two tables preserve raw data + clean UI
- User never sees pipeline complexity

**Start with README.md and 0-scope.md. Go! ğŸš€**

---

**Document Version**: 2.1 (Updated with Complete Darwin Context)
**Date**: 2025-10-28
**Author**: Claude (Session 1 - Handoff to Session 2)
**Status**: Ready for execution

**Changes from v1.0**:
- Added complete pipeline (Observe â†’ Cluster â†’ Normalize â†’ Canonical)
- Updated LOC to ~1800, 10 batches instead of 9
- **v2.1**: Added complete Darwin context (money flow, account purposes, pain points, geographic context)
